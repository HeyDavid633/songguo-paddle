python attention_flash.py -batch_size 1 -head_dim 32 -seq_len 128
python attention_flash.py -batch_size 1 -head_dim 32 -seq_len 256
python attention_flash.py -batch_size 1 -head_dim 32 -seq_len 512
python attention_flash.py -batch_size 1 -head_dim 32 -seq_len 1024
python attention_flash.py -batch_size 1 -head_dim 32 -seq_len 2048
python attention_flash.py -batch_size 1 -head_dim 32 -seq_len 4096
python attention_flash.py -batch_size 8 -head_dim 32 -seq_len 128
python attention_flash.py -batch_size 8 -head_dim 32 -seq_len 256
python attention_flash.py -batch_size 8 -head_dim 32 -seq_len 512
python attention_flash.py -batch_size 8 -head_dim 32 -seq_len 1024
python attention_flash.py -batch_size 8 -head_dim 32 -seq_len 2048
python attention_flash.py -batch_size 8 -head_dim 32 -seq_len 4096
python attention_flash.py -batch_size 16 -head_dim 32 -seq_len 128
python attention_flash.py -batch_size 16 -head_dim 32 -seq_len 256
python attention_flash.py -batch_size 16 -head_dim 32 -seq_len 512
python attention_flash.py -batch_size 16 -head_dim 32 -seq_len 1024
python attention_flash.py -batch_size 16 -head_dim 32 -seq_len 2048
python attention_flash.py -batch_size 16 -head_dim 32 -seq_len 4096
python attention_flash.py -batch_size 1 -head_dim 64 -seq_len 128
python attention_flash.py -batch_size 1 -head_dim 64 -seq_len 256
python attention_flash.py -batch_size 1 -head_dim 64 -seq_len 512
python attention_flash.py -batch_size 1 -head_dim 64 -seq_len 1024
python attention_flash.py -batch_size 1 -head_dim 64 -seq_len 2048
python attention_flash.py -batch_size 1 -head_dim 64 -seq_len 4096
python attention_flash.py -batch_size 8 -head_dim 64 -seq_len 128
python attention_flash.py -batch_size 8 -head_dim 64 -seq_len 256
python attention_flash.py -batch_size 8 -head_dim 64 -seq_len 512
python attention_flash.py -batch_size 8 -head_dim 64 -seq_len 1024
python attention_flash.py -batch_size 8 -head_dim 64 -seq_len 2048
python attention_flash.py -batch_size 8 -head_dim 64 -seq_len 4096
python attention_flash.py -batch_size 16 -head_dim 64 -seq_len 128
python attention_flash.py -batch_size 16 -head_dim 64 -seq_len 256
python attention_flash.py -batch_size 16 -head_dim 64 -seq_len 512
python attention_flash.py -batch_size 16 -head_dim 64 -seq_len 1024
python attention_flash.py -batch_size 16 -head_dim 64 -seq_len 2048
python attention_flash.py -batch_size 16 -head_dim 64 -seq_len 4096

python attention_standard.py -batch_size 1 -head_dim 32 -seq_len 128
python attention_standard.py -batch_size 1 -head_dim 32 -seq_len 256
python attention_standard.py -batch_size 1 -head_dim 32 -seq_len 512
python attention_standard.py -batch_size 1 -head_dim 32 -seq_len 1024
python attention_standard.py -batch_size 1 -head_dim 32 -seq_len 2048
python attention_standard.py -batch_size 1 -head_dim 32 -seq_len 4096
python attention_standard.py -batch_size 8 -head_dim 32 -seq_len 128
python attention_standard.py -batch_size 8 -head_dim 32 -seq_len 256
python attention_standard.py -batch_size 8 -head_dim 32 -seq_len 512
python attention_standard.py -batch_size 8 -head_dim 32 -seq_len 1024
python attention_standard.py -batch_size 8 -head_dim 32 -seq_len 2048
python attention_standard.py -batch_size 8 -head_dim 32 -seq_len 4096
python attention_standard.py -batch_size 16 -head_dim 32 -seq_len 128
python attention_standard.py -batch_size 16 -head_dim 32 -seq_len 256
python attention_standard.py -batch_size 16 -head_dim 32 -seq_len 512
python attention_standard.py -batch_size 16 -head_dim 32 -seq_len 1024
python attention_standard.py -batch_size 16 -head_dim 32 -seq_len 2048
python attention_standard.py -batch_size 16 -head_dim 32 -seq_len 4096
python attention_standard.py -batch_size 1 -head_dim 64 -seq_len 128
python attention_standard.py -batch_size 1 -head_dim 64 -seq_len 256
python attention_standard.py -batch_size 1 -head_dim 64 -seq_len 512
python attention_standard.py -batch_size 1 -head_dim 64 -seq_len 1024
python attention_standard.py -batch_size 1 -head_dim 64 -seq_len 2048
python attention_standard.py -batch_size 1 -head_dim 64 -seq_len 4096
python attention_standard.py -batch_size 8 -head_dim 64 -seq_len 128
python attention_standard.py -batch_size 8 -head_dim 64 -seq_len 256
python attention_standard.py -batch_size 8 -head_dim 64 -seq_len 512
python attention_standard.py -batch_size 8 -head_dim 64 -seq_len 1024
python attention_standard.py -batch_size 8 -head_dim 64 -seq_len 2048
python attention_standard.py -batch_size 8 -head_dim 64 -seq_len 4096
python attention_standard.py -batch_size 16 -head_dim 64 -seq_len 128
python attention_standard.py -batch_size 16 -head_dim 64 -seq_len 256
python attention_standard.py -batch_size 16 -head_dim 64 -seq_len 512
python attention_standard.py -batch_size 16 -head_dim 64 -seq_len 1024
python attention_standard.py -batch_size 16 -head_dim 64 -seq_len 2048
python attention_standard.py -batch_size 16 -head_dim 64 -seq_len 4096